{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.1 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "2ea0fd5b075136882d9beed19543467ee270e6365acd547b142b321a53a483a3"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, subprocess, json, time, pickle, winwifi_api\n",
    "from itertools import islice\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = os.getcwd()\n",
    "data_quality = folder_path+\"\\data\\\\quality\"\n",
    "data_rssi = folder_path+\"\\data\\\\rssi\"\n",
    "data_all = folder_path+\"\\data\\\\all\"\n",
    "model_qual = folder_path + \"\\model.pkl\"\n",
    "model_rssi = folder_path + \"\\model2.pkl\"\n",
    "\n",
    "model_file = model_qual\n",
    "data_path = data_quality\n",
    "\n",
    "def parse_output(output):\n",
    "    ssid = bssid = quality = None\n",
    "    ssid_line = bssid_line = -100\n",
    "    results = []\n",
    "    for num, line in enumerate(output.split(\"\\n\")):\n",
    "        line = line.strip()\n",
    "        if line.startswith(\"SSID\"):\n",
    "            ssid = \" \".join(line.split()[3:]).strip()\n",
    "            ssid_line = num\n",
    "            if ssid == '':\n",
    "                ssid = 'None'\n",
    "        elif line.startswith(\"BSSID\"):\n",
    "            bssid = \":\".join(line.split(\":\")[1:]).strip()\n",
    "            bssid_line = num\n",
    "        elif num == bssid_line + 1:\n",
    "            quality = int(\":\".join(line.split(\":\")[1:]).strip().replace(\"%\", \"\"))\n",
    "            if bssid is not None:\n",
    "                ap = {\"ssid\":ssid, \"bssid\":bssid, \"quality\" : quality}\n",
    "                results.append(ap)\n",
    "    return results\n",
    "\n",
    "def make_str(output):\n",
    "    try:                        output = output.decode(\"utf8\",errors='ignore')\n",
    "    except UnicodeDecodeError:  output = output.decode(\"utf16\",errors='ignore')\n",
    "    except AttributeError:      pass\n",
    "    return                      output\n",
    "\n",
    "def get_sample():\n",
    "    netsh = subprocess.Popen(\"netsh wlan show networks mode=bssid\", stdout=subprocess.PIPE, shell=True)\n",
    "    (out, _) = netsh.communicate()\n",
    "    results = parse_output(make_str(out))\n",
    "    sample = {ap['ssid'] + \" \" + ap['bssid']: ap['quality'] for ap in results}\n",
    "    return sample\n",
    "    \n",
    "def get_sample2():\n",
    "    results = winwifi_api.wifi_scan()\n",
    "    sample = []\n",
    "    for ap in results:\n",
    "        sample = {ap[0] + \" \" + ap[1] + \" \" + str(ap[3]): ap[4] for ap in results}\n",
    "    return sample\n",
    "\n",
    "def get_all():\n",
    "    results = winwifi_api.wifi_scan()\n",
    "    sample = []\n",
    "    for ap in results:\n",
    "        sample.append([ap[0] + \" \" + ap[1], ap[2], ap[3], ap[4], ap[5]])\n",
    "    return sample\n",
    "\n",
    "    \n",
    "def get_pipeline(clf=RandomForestClassifier(n_estimators=100, class_weight=\"balanced\", max_features = \"auto\")):\n",
    "    return make_pipeline(DictVectorizer(sparse=False), clf)\n",
    "\n",
    "def get_train_data(folder=None):\n",
    "    X = []\n",
    "    y = []\n",
    "    for file_name in os.listdir(folder):\n",
    "        if file_name.endswith(\".txt\"):\n",
    "            data = []\n",
    "            with open(os.path.join(folder, file_name)) as f:\n",
    "                for line in f:\n",
    "                    data.append(json.loads(line))\n",
    "            X.extend(data)\n",
    "            y.extend([file_name.rstrip(\".txt\")] * len(data))\n",
    "    return X, y\n",
    "\n",
    "def get_model(model = model_file):\n",
    "    try:\n",
    "        model_file = folder_path + \"\\model.pkl\"\n",
    "        with open(model, \"rb\") as f:\n",
    "            lp = pickle.load(f)\n",
    "        return lp\n",
    "    except: raise ValueError(\"Can not find model file!\")\n",
    "\n",
    "def train_model(path = data_path, model = model_file):\n",
    "    X, y = get_train_data(path)\n",
    "    if len(X) == 0: raise ValueError(\"Can not find any trained locations!\")\n",
    "    lp = get_pipeline()\n",
    "    lp.fit(X, y)\n",
    "    with open(model, \"wb\") as f:\n",
    "        pickle.dump(lp, f)\n",
    "\n",
    "def learn(label, n=1):\n",
    "    label_path = os.path.join(data_path, label + \".txt\")\n",
    "    label_path2 = os.path.join(data_rssi, label + \"_rssi.txt\")\n",
    "    label_path3 = os.path.join(data_all, label + \"_all.txt\")\n",
    "\n",
    "    try:\n",
    "        new_sample  = get_sample()\n",
    "        new_rssi = get_sample2()\n",
    "        new_all = get_all()\n",
    "        print(\"Number of APs in range: \", len(new_rssi))\n",
    "        if new_sample:\n",
    "            write_data(label_path, new_sample)\n",
    "            write_data(label_path2, new_rssi)\n",
    "            write_data(label_path3, new_all)\n",
    "            print(\"Done, number of old measurement of\", locations(data_path, label))\n",
    "            print(\"Done, number of rssi measurement of\", locations(data_rssi, label + \"_rssi\"))\n",
    "\n",
    "    except: \n",
    "        print(\"Something go wrong.\")\n",
    "    train_model()\n",
    "    \n",
    "def write_data(label_path, data):\n",
    "    with open(label_path, \"a\") as f:\n",
    "        f.write(json.dumps(data))\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "def write_data2(label_path, data):\n",
    "    with open(label_path, \"a\") as f:\n",
    "        f.write('%s\\n' % data)\n",
    "\n",
    "def locations(path=None, loc=None):\n",
    "    _, y = get_train_data(path)\n",
    "    if len(y) == 0: \n",
    "        raise ValueError(\"Can not find any trained locations!\")\n",
    "    else:\n",
    "        occurrences = Counter(y)\n",
    "        if loc:\n",
    "            for key, value in occurrences.items():\n",
    "                if key == loc:\n",
    "                    return(\"{}: {}\".format(key, value))\n",
    "        else:\n",
    "            for key, value in occurrences.items():\n",
    "                print(\"{}: {}\".format(key, value))\n",
    "\n",
    "def print_proba():\n",
    "    out = predict_proba()\n",
    "    out = {k: v for k, v in sorted(out.items(), key=lambda item: item[1], reverse = True)}\n",
    "    out = dict(islice(out.items(), 4))\n",
    "    return out\n",
    "\n",
    "def predict_proba( lp = get_model(), data_sample =  get_sample() ):\n",
    "    out = dict(zip(lp.classes_, lp.predict_proba(data_sample)[0]))\n",
    "    out = {k: v for k, v in sorted(out.items(), key=lambda item: item[1], reverse = True)}\n",
    "    return out\n",
    "\n",
    "def predict():\n",
    "    lp = get_model()\n",
    "    data_sample = get_sample()\n",
    "    return lp.predict(data_sample)[0]\n",
    "\n",
    "\n",
    "def crossval(data = data_path, model = get_model, clf=None, X=None, y=None, folds=10, n=5):\n",
    "    if X is None or y is None:\n",
    "        X, y = get_train_data(data)\n",
    "    if len(X) < folds:  raise ValueError('There are not enough samples ({}). Need at least {}.'.format(len(X), folds))\n",
    "    clf = clf or model\n",
    "    tot = 0\n",
    "    print(\"KFold folds={}, running {} times\".format(folds, n))\n",
    "    for i in range(n):\n",
    "        res = cross_val_score(clf, X, y, cv=folds).mean()\n",
    "        tot += res\n",
    "        print(\"{}/{}: {}\".format(i + 1, n, res))\n",
    "    print(\"-------- total --------\")\n",
    "    print(tot / n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sched, time\n",
    "s = sched.scheduler(time.time, time.sleep)\n",
    "def do_something(a): \n",
    "    print(\"Doing stuff...\")\n",
    "    s.enter(a, 2, learn, argument=('office_desk_filip',))\n",
    "    s.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "tags": []
   },

   "source": [
    "locations(data_path)\n",
    "for i in range(60):\n",
    "    print(\"measuring time:\", i+1)\n",
    "    do_something(10)\n",
    "\n",
    "locations(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quality model test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "office_1_1_qual: 126\noffice_1_2_qual: 120\noffice_2_1_qual: 180\noffice_2_2_qual: 118\noffice_3_1_qual: 180\noffice_3_2_qual: 120\noffice_3_3_qual: 120\n"
     ]
    }
   ],
   "source": [
    "locations(data_quality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(data_quality, model_qual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'office_1_1_qual': 0.82,\n",
       " 'office_1_2_qual': 0.12,\n",
       " 'office_2_2_qual': 0.05,\n",
       " 'office_3_1_qual': 0.01,\n",
       " 'office_2_1_qual': 0.0,\n",
       " 'office_3_2_qual': 0.0,\n",
       " 'office_3_3_qual': 0.0}"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "predict_proba(get_model(model_qual), get_sample() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "KFold folds=10, running 5 times\n",
      "1/5: 0.752147766323024\n",
      "2/5: 0.7459407216494846\n",
      "3/5: 0.7562714776632301\n",
      "4/5: 0.7510524054982818\n",
      "5/5: 0.7469072164948455\n",
      "-------- total --------\n",
      "0.7504639175257732\n"
     ]
    }
   ],
   "source": [
    "crossval(data_quality, get_model(model_qual))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RSSI model test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "office_1_1_rssi: 125\noffice_1_2_rssi: 119\noffice_2_1_rssi: 179\noffice_2_2_rssi: 116\noffice_3_1_rssi: 179\noffice_3_2_rssi: 119\noffice_3_3_rssi: 120\n"
     ]
    }
   ],
   "source": [
    "locations(data_rssi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(data_rssi, model_rssi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'office_1_1_rssi': 0.5,\n",
       " 'office_1_2_rssi': 0.2,\n",
       " 'office_2_1_rssi': 0.09,\n",
       " 'office_2_2_rssi': 0.09,\n",
       " 'office_3_1_rssi': 0.06,\n",
       " 'office_3_3_rssi': 0.06,\n",
       " 'office_3_2_rssi': 0.0}"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "predict_proba(get_model(model_rssi), get_sample2())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "KFold folds=10, running 5 times\n",
      "1/5: 0.6552521929824562\n",
      "2/5: 0.6489912280701754\n",
      "3/5: 0.654265350877193\n",
      "4/5: 0.6604605263157894\n",
      "5/5: 0.6552412280701755\n",
      "-------- total --------\n",
      "0.6548421052631579\n"
     ]
    }
   ],
   "source": [
    "crossval(data_rssi, get_model(model_rssi))"
   ]
  }
 ]
}
