{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.1 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "2ea0fd5b075136882d9beed19543467ee270e6365acd547b142b321a53a483a3"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, subprocess, json, time, pickle\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = os.getcwd()\n",
    "data_path = folder_path+\"\\data\"\n",
    "model_file = folder_path + \"\\model.pkl\"\n",
    "\n",
    "def parse_output(output):\n",
    "    ssid = bssid = quality = None\n",
    "    ssid_line = bssid_line = -100\n",
    "    results = []\n",
    "    for num, line in enumerate(output.split(\"\\n\")):\n",
    "        line = line.strip()\n",
    "        if line.startswith(\"SSID\"):\n",
    "            ssid = \" \".join(line.split()[3:]).strip()\n",
    "            ssid_line = num\n",
    "            if ssid == '':\n",
    "                ssid = 'None'\n",
    "        elif line.startswith(\"BSSID\"):\n",
    "            bssid = \":\".join(line.split(\":\")[1:]).strip()\n",
    "            bssid_line = num\n",
    "        elif num == bssid_line + 1:\n",
    "            quality = int(\":\".join(line.split(\":\")[1:]).strip().replace(\"%\", \"\"))\n",
    "            if bssid is not None:\n",
    "                ap = {\"ssid\":ssid, \"bssid\":bssid, \"quality\" : quality}\n",
    "                results.append(ap)\n",
    "    return results\n",
    "\n",
    "def make_str(output):\n",
    "    try:                        output = output.decode(\"utf8\",errors='ignore')\n",
    "    except UnicodeDecodeError:  output = output.decode(\"utf16\",errors='ignore')\n",
    "    except AttributeError:      pass\n",
    "    return                      output\n",
    "\n",
    "def get_sample():\n",
    "    netsh = subprocess.Popen(\"netsh wlan show networks mode=bssid\", stdout=subprocess.PIPE, shell=True)\n",
    "    (out, _) = netsh.communicate()\n",
    "    results = parse_output(make_str(out))\n",
    "    sample = {ap['ssid'] + \" \" + ap['bssid']: ap['quality'] for ap in results}\n",
    "    return sample\n",
    "\n",
    "\n",
    "\n",
    "def get_pipeline(clf=RandomForestClassifier(n_estimators=100, class_weight=\"balanced\")):\n",
    "    return make_pipeline(DictVectorizer(sparse=False), clf)\n",
    "\n",
    "def get_train_data(folder=None):\n",
    "    X = []\n",
    "    y = []\n",
    "    for file_name in os.listdir(folder):\n",
    "        if file_name.endswith(\".txt\"):\n",
    "            data = []\n",
    "            with open(os.path.join(folder, file_name)) as f:\n",
    "                for line in f:\n",
    "                    data.append(json.loads(line))\n",
    "            X.extend(data)\n",
    "            y.extend([file_name.rstrip(\".txt\")] * len(data))\n",
    "    return X, y\n",
    "\n",
    "def get_model():\n",
    "    try:\n",
    "        model_file = folder_path + \"\\model.pkl\"\n",
    "        with open(model_file, \"rb\") as f:\n",
    "            lp = pickle.load(f)\n",
    "        return lp\n",
    "    except: raise ValueError(\"Can not find model file!\")\n",
    "\n",
    "def train_model():\n",
    "    X, y = get_train_data(data_path)\n",
    "    if len(X) == 0: raise ValueError(\"Can not find any trained locations!\")\n",
    "    lp = get_pipeline()\n",
    "    lp.fit(X, y)\n",
    "    with open(model_file, \"wb\") as f:\n",
    "        pickle.dump(lp, f)\n",
    "\n",
    "def learn(label, n=1):\n",
    "    label_path = os.path.join(data_path, label + \".txt\")\n",
    "    try:\n",
    "        new_sample = get_sample()\n",
    "        if new_sample:\n",
    "            write_data(label_path, new_sample)\n",
    "            print(\"Done, number of measurement of\", locations(data_path, label))\n",
    "    except: pass\n",
    "    train_model()\n",
    "    \n",
    "def write_data(label_path, data):\n",
    "    with open(label_path, \"a\") as f:\n",
    "        f.write(json.dumps(data))\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "\n",
    "def locations(path=None, loc=None):\n",
    "    _, y = get_train_data(path)\n",
    "    if len(y) == 0: \n",
    "        raise ValueError(\"Can not find any trained locations!\")\n",
    "    else:\n",
    "        occurrences = Counter(y)\n",
    "        if loc:\n",
    "            for key, value in occurrences.items():\n",
    "                if key == loc:\n",
    "                    return(\"{}: {}\".format(key, value))\n",
    "        else:\n",
    "            for key, value in occurrences.items():\n",
    "                print(\"{}: {}\".format(key, value))\n",
    "\n",
    "def predict_proba():\n",
    "    lp = get_model()\n",
    "    data_sample = get_sample()\n",
    "    print(json.dumps(dict(zip(lp.classes_, lp.predict_proba(data_sample)[0]))))\n",
    "\n",
    "def predict():\n",
    "    lp = get_model()\n",
    "    data_sample = get_sample()\n",
    "    return lp.predict(data_sample)[0]\n",
    "\n",
    "\n",
    "def crossval(clf=None, X=None, y=None, folds=10, n=5):\n",
    "    if X is None or y is None:\n",
    "        X, y = get_train_data(data_path)\n",
    "    if len(X) < folds:  raise ValueError('There are not enough samples ({}). Need at least {}.'.format(len(X), folds))\n",
    "    clf = clf or get_model()\n",
    "    tot = 0\n",
    "    print(\"KFold folds={}, running {} times\".format(folds, n))\n",
    "    for i in range(n):\n",
    "        res = cross_val_score(clf, X, y, cv=folds).mean()\n",
    "        tot += res\n",
    "        print(\"{}/{}: {}\".format(i + 1, n, res))\n",
    "    print(\"-------- total --------\")\n",
    "    print(tot / n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "home_bedroom: 69\nhome_kitchen: 30\nhome_livingroom: 142\nhome_loby: 30\noffice_desk: 81\noffice_loby: 25\noffice_meetingroom: 45\noffice_view: 10\n"
     ]
    }
   ],
   "source": [
    "locations(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Done, number of measurement of office_desk: 82\n"
     ]
    }
   ],
   "source": [
    "learn(\"office_desk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{\"home_bedroom\": 0.0, \"home_kitchen\": 0.0, \"home_livingroom\": 0.0, \"home_loby\": 0.0, \"office_desk\": 0.98, \"office_loby\": 0.0, \"office_meetingroom\": 0.02, \"office_view\": 0.0}\n"
     ]
    }
   ],
   "source": [
    "predict_proba()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}